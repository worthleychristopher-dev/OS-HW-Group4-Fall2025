2009:
  L1 cache reference:                  0.5 ns
  Branch mispredict:                   5 ns
  L2 cache reference:                  7 ns
  Mutex lock/unlock:                   25 ns
  Main memory reference:               100 ns
  Read 1 MB sequentially from memory:  250,000 ns
  Round trip within same datacenter:   500,000 ns
  Disk seek:                           10,000,000 ns
  Read 1 MB sequentially from disk:    20,000,000 ns
  Send packet CA->Netherlands->CA:     150,000,000 ns

Updated:                                                 
  L1 cache reference:                  1 ns
  Branch mispredict:                   3 ns
  L2 cache reference:                  4 ns
  Mutex lock/unlock:                   17 ns
  Main memory reference:               100 ns
  Read 1 MB sequentially from memory:  935 ns
  Round trip within same datacenter:   500,000 ns
  Disk seek:                           2,000,000 ns
  Read 1 MB sequentially from disk:    412,000 ns
  Send packet CA->Netherlands->CA:     150,000,000 ns

Reference: Scott, Colin. “Latency Numbers Every Programmer Should Know By Year.” colin-scott.github.io, accessed 12 Nov. 2025, https://colin-scott.github.io/personal_website/research/interactive_latency.html

The numbers have improved in most categories. Although L1 cache seems to have gotten slower, I believe the issue is a rounding error. 
The only other branches that didn't improve were Main memory reference, Round trip within same datacenter, and  Sending a packet from CA->Netherlands->CA, these values stayed the same.

